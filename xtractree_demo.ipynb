{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xtractree_demo_v20220115.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SOUsvK3M6pk"
      },
      "source": [
        "# How to use XtracTree?\n",
        "In this notebook, we demonstrate the usage of XtracTree for a Decision Tree Classifier. Parameter \"exp\" can be adjusted to do the experiments with a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUJRPnMhn45U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter, OrderedDict\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "#\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (classification_report, \n",
        "                             confusion_matrix, \n",
        "                             roc_curve, \n",
        "                             auc)\n",
        "from sklearn.utils import Bunch\n",
        "import lightgbm\n",
        "#\n",
        "# PANDAS OPTIONS\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "# AVOID SKLEARN USER WARNING (DATA DEPENDENT)\n",
        "def warn(*args, **kwargs):\n",
        "  pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuqrWN_jNfeJ"
      },
      "source": [
        "# XtracTree Class Definition\n",
        "Here we pasted the XtracTree class in the notebook for the sake of the demo. It is possible to save the class in a separate module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np9nYnCgn8A2"
      },
      "source": [
        "class XtracTree:\n",
        "  def __init__(self, estimator, x_train, x_test, \n",
        "               sample_id=None, sample_ids=None, out=None):\n",
        "    self.estimator = estimator\n",
        "    self.x_train = x_train\n",
        "    self.x_test = x_test\n",
        "    self.sample_id = sample_id\n",
        "    self.sample_ids = sample_ids\n",
        "    self.out = out\n",
        "  # END OF FUNCTION __init__\n",
        "  #\n",
        "  def __getstate__(self):\n",
        "    return self.__dict__.copy()\n",
        "  # END OF FUNCTION __getstate__\n",
        "  #\n",
        "  def trees_to_dataframe(self):\n",
        "    \"\"\"Parse the fitted model and return in an easy-to-read pandas DataFrame.\n",
        "    The returned DataFrame has the following columns.\n",
        "      - ``tree_index`` : int64, which tree a node belongs to. 0-based, so a\n",
        "        value of ``6``, for example, means \"this node is in the 7th tree\".\n",
        "      - ``node_depth`` : int64, how far a node is from the root of the tree.\n",
        "        The root node has a value of ``1``, its direct children are ``2``, etc.\n",
        "      - ``node_index`` : str, unique identifier for a node.\n",
        "      - ``left_child`` : str, ``node_index`` of the child node to the left of\n",
        "        a split. ``None`` for leaf nodes.\n",
        "      - ``right_child`` : str, ``node_index`` of the child node to the \n",
        "        right of a split. ``None`` for leaf nodes.\n",
        "      - ``parent_index`` : str, ``node_index`` of this node's parent.\n",
        "        ``None`` for the root node.\n",
        "      - ``split_feature`` : str, name of the feature used for splitting.\n",
        "        ``None`` for leaf nodes.\n",
        "      - ``split_gain`` : float64, gain from adding this split to the tree.\n",
        "        ``NaN`` for leaf nodes.\n",
        "      - ``threshold`` : float64, value of the feature used to decide which\n",
        "        side of the split a record will go down. ``NaN`` for leaf nodes.\n",
        "      - ``decision_type`` : str, logical operator describing how to compare\n",
        "        a value to ``threshold``.\n",
        "        For example, ``split_feature = \"Column_10\", threshold = 15,\n",
        "        decision_type = \"<=\"`` means that\n",
        "        records where ``Column_10 <= 15`` follow the left side of the split,\n",
        "        otherwise follows the right side of the split. ``None`` for leaf nodes.\n",
        "      - ``missing_direction`` : str, split direction that missing values\n",
        "        should go to. ``None`` for leaf nodes.\n",
        "      - ``missing_type`` : str, describes what types of values\n",
        "        are treated as missing.\n",
        "      - ``value`` : float64, predicted value for this leaf node, multiplied\n",
        "        by the learning rate.\n",
        "      - ``weight`` : float64 or int64, sum of hessian (second-order\n",
        "        derivative of objective), summed over observations that fall\n",
        "        in this node.\n",
        "      - ``count`` : int64, number of records in the training data that\n",
        "        fall into this node.\n",
        "    Returns\n",
        "    -------\n",
        "    result : pandas DataFrame\n",
        "        Returns a pandas DataFrame of the parsed model.\n",
        "    \"\"\"\n",
        "    if self.num_trees() == 0:\n",
        "      msg='There are no trees in this Booster and thus nothing to parse'\n",
        "      raise LightGBMError(msg)\n",
        "    # ENDIF\n",
        "    def _is_split_node(tree):\n",
        "        return 'split_index' in tree.keys()\n",
        "    # END OF FUNCTION _is_split_node\n",
        "    #\n",
        "    def create_node_record(tree, node_depth=1, tree_index=None,\n",
        "                            feature_names=None, parent_node=None):\n",
        "        def _get_node_index(tree, tree_index):\n",
        "            tree_num = f'{tree_index}-' if tree_index is not None else ''\n",
        "            is_split = _is_split_node(tree)\n",
        "            node_type = 'S' if is_split else 'L'\n",
        "            # if a single node tree it won't have `leaf_index` so return 0\n",
        "            node_num = tree.get('split_index' if is_split else 'leaf_index', 0)\n",
        "            return f\"{tree_num}{node_type}{node_num}\"\n",
        "        # END OF FUNCTION _get_node_index\n",
        "        #\n",
        "        def _get_split_feature(tree, feature_names):\n",
        "            if _is_split_node(tree):\n",
        "                if feature_names is not None:\n",
        "                    feature_name = feature_names[tree['split_feature']]\n",
        "                else:\n",
        "                    feature_name = tree['split_feature']\n",
        "            else:\n",
        "                feature_name = None\n",
        "            return feature_name\n",
        "        # END OF FUNCTION _get_split_feature\n",
        "        #\n",
        "        def _is_single_node_tree(tree):\n",
        "            return set(tree.keys()) == {'leaf_value'}\n",
        "        # END OF FUNCTION _is_single_node_tree\n",
        "        #\n",
        "        # CREATE NODE RECORD, POPULATE UNIVERSAL DATA MEMBERS\n",
        "        node = OrderedDict()\n",
        "        node['tree_index'] = tree_index\n",
        "        node['node_depth'] = node_depth\n",
        "        node['node_index'] = _get_node_index(tree, tree_index)\n",
        "        node['left_child'] = None\n",
        "        node['right_child'] = None\n",
        "        node['parent_index'] = parent_node\n",
        "        node['split_feature'] = _get_split_feature(tree, feature_names)\n",
        "        node['split_gain'] = None\n",
        "        node['threshold'] = None\n",
        "        node['decision_type'] = None\n",
        "        node['missing_direction'] = None\n",
        "        node['missing_type'] = None\n",
        "        node['value'] = None\n",
        "        #node['weight'] = None\n",
        "        node['count'] = None\n",
        "        #\n",
        "        # UPDATE VALUES TO REFLECT NODE TYPE (LEAF OR SPLIT)\n",
        "        if _is_split_node(tree):\n",
        "            node['left_child'] = _get_node_index(tree['left_child'], tree_index)\n",
        "            node['right_child'] = _get_node_index(tree['right_child'], tree_index)\n",
        "            node['split_gain'] = tree['split_gain']\n",
        "            node['threshold'] = tree['threshold']\n",
        "            node['decision_type'] = tree['decision_type']\n",
        "            node['missing_direction'] = 'left' if tree['default_left'] else 'right'\n",
        "            node['missing_type'] = tree['missing_type']\n",
        "            node['value'] = tree['internal_value']\n",
        "            #node['weight'] = tree['internal_weight']\n",
        "            node['count'] = tree['internal_count']\n",
        "        else:\n",
        "            node['value'] = tree['leaf_value']\n",
        "            if not _is_single_node_tree(tree):\n",
        "                #node['weight'] = tree['leaf_weight']\n",
        "                node['count'] = tree['leaf_count']\n",
        "\n",
        "        return node\n",
        "    # END OF FUNCTION create_node_record\n",
        "    #\n",
        "    def tree_dict_to_node_list(\n",
        "        tree, node_depth=1, tree_index=None,\n",
        "        feature_names=None, parent_node=None):\n",
        "      node = create_node_record(\n",
        "        tree,\n",
        "        node_depth=node_depth,\n",
        "        tree_index=tree_index,\n",
        "        feature_names=feature_names,\n",
        "        parent_node=parent_node\n",
        "      )\n",
        "      res = [node]\n",
        "      if _is_split_node(tree):\n",
        "        # TRAVERSE THE NEXT LEVEL OF THE TREE\n",
        "        children = ['left_child', 'right_child']\n",
        "        for child in children:\n",
        "          subtree_list = tree_dict_to_node_list(\n",
        "            tree[child],\n",
        "            node_depth=node_depth + 1,\n",
        "            tree_index=tree_index,\n",
        "            feature_names=feature_names,\n",
        "            parent_node=node['node_index'])\n",
        "          # IN TREE FORMAT, \"subtree_list\" = LIST OF NODE RECORDS (DICTS)\n",
        "          # AND ADD NODE TO THE LIST\n",
        "          res.extend(subtree_list)\n",
        "      return res\n",
        "    # END OF FUNCTION tree_dict_to_node_list\n",
        "    #\n",
        "    model_dict = self.dump_model()\n",
        "    feature_names = model_dict['feature_names']\n",
        "    model_list = []\n",
        "    for tree in model_dict['tree_info']:\n",
        "      model_list.extend(\n",
        "        tree_dict_to_node_list(\n",
        "          tree['tree_structure'],\n",
        "          tree_index=tree['tree_index'],\n",
        "          feature_names=feature_names\n",
        "        )\n",
        "      )\n",
        "    # ENDFOR\n",
        "    return pd.DataFrame(model_list, columns=model_list[0].keys())\n",
        "  # END OF FUNCTION trees_to_dataframe\n",
        "  #\n",
        "  def build_dtree_rules(estimator, n_trees, x_train, l2w):\n",
        "    \"\"\"Extract decision rules with splitting thresholds and probabilities.\n",
        "    \"\"\"\n",
        "    # GET USEFULL INFO ABOUT TREE STRUCTURE\n",
        "    # WITH estimator.tree.__getstate__()['nodes']\n",
        "    # OR import sklearn, help(sklearn.tree._tree.Tree)\n",
        "    n_nodes = estimator.tree_.node_count\n",
        "    children_left = estimator.tree_.children_left\n",
        "    children_right = estimator.tree_.children_right\n",
        "    feature = estimator.tree_.feature\n",
        "    threshold = estimator.tree_.threshold\n",
        "    n_node_samples = estimator.tree_.n_node_samples\n",
        "    value = estimator.tree_.value\n",
        "    weighted_n_node_samples = estimator.tree_.weighted_n_node_samples\n",
        "    node_depth = np.zeros(shape = n_nodes, dtype = np.int64)\n",
        "    is_leaves = np.zeros(shape = n_nodes, dtype = bool)\n",
        "    stack = [(0, -1)] # SEED IS ROOT NODE ID AND ITS PARENT DEPTH\n",
        "    while len(stack) > 0:\n",
        "      node_id, parent_depth = stack.pop()\n",
        "      node_depth[node_id] = parent_depth + 1\n",
        "      # IF TEST NODE\n",
        "      if (children_left[node_id] != children_right[node_id]):\n",
        "        stack.append((children_left[node_id], parent_depth + 1))\n",
        "        stack.append((children_right[node_id], parent_depth + 1))\n",
        "      else:\n",
        "        is_leaves[node_id] = True\n",
        "      # ENDIF\n",
        "    # ENDWHILE\n",
        "    bgn=\"        if state == \"\n",
        "    for i in range(n_nodes):\n",
        "      if is_leaves[i]:\n",
        "        irow = bgn+\"%s: return %s\\n\" % (\n",
        "          i, ((value[i][0,1] / weighted_n_node_samples[i]) / n_trees)\n",
        "          )\n",
        "      else:\n",
        "        irow = bgn+\"%s: state = (%s if x['%s'] <= %s else %s)\\n\" % (\n",
        "          i, \n",
        "          children_left[i],\n",
        "          x_train.columns[feature[i]],\n",
        "          threshold[i],\n",
        "          children_right[i]\n",
        "        )\n",
        "      # ENDIF\n",
        "      l2w.append(irow)\n",
        "    # ENDFOR\n",
        "    return l2w\n",
        "  # END OF FUNCTION build_dtree_rules\n",
        "  #\n",
        "  def build_model(self):\n",
        "    \"\"\"Build the global architecture of the bagging algorithm.\n",
        "    It is designed such that it is an executable if self.out is \n",
        "    saved as .py file. \n",
        "    \"\"\"\n",
        "    # WRITE THE FIRST LINE OF THE FILE\n",
        "    # STORE THE CONTENT OF THE FILE TO BE WRITTEN IN l2w\n",
        "    l2w = [\"import numpy as np\\n\"]\n",
        "    l2w.append(\"\\n\")\n",
        "    l2w.append(\"def estimator_tree(x, num_tree):\\n\")\n",
        "    #\n",
        "    if 'LGBM' in str(self.estimator):\n",
        "      dfmodel=XtracTree.trees_to_dataframe(self.estimator._Booster)\n",
        "      nrows=len(dfmodel)\n",
        "      nsamples=dfmodel.iloc[0][\"count\"]\n",
        "      n_trees=self.estimator.n_estimators\n",
        "      for itree in range(n_trees):\n",
        "        l2w.append(\"  if num_tree == %s:\\n\" % itree)\n",
        "        dftree=dfmodel[dfmodel.tree_index==itree]\n",
        "        node_depth=np.unique(dftree.node_depth)\n",
        "        state,cnt=0,0\n",
        "        l2w.append(\"    state=%s\\n\" % state)\n",
        "        msg=\"    if state==\"\n",
        "        for idepth in node_depth:\n",
        "          indx=dftree.node_depth==idepth\n",
        "          tmpdf=dftree[indx]\n",
        "          for nrow in range(len(tmpdf)):\n",
        "            irow=tmpdf.iloc[nrow]\n",
        "            if irow.decision_type==\"<=\":\n",
        "              msg=\"    if state==\"\n",
        "              l2w.append(msg+\"%s: state=(%s if x['%s'] %s %s else %s)\\n\" % (\n",
        "                state,\n",
        "                state+1+cnt,\n",
        "                irow.split_feature,\n",
        "                irow.decision_type,\n",
        "                irow.threshold,\n",
        "                state+2+cnt)\n",
        "              )\n",
        "              cnt+=1\n",
        "            else:\n",
        "              l2w.append(msg+'%s: return %s\\n' % (\n",
        "                state, irow.value)\n",
        "              )\n",
        "              cnt-=1\n",
        "            # ENDIF\n",
        "            state+=1\n",
        "          # ENDFOR\n",
        "        # ENDFOR\n",
        "      # ENDFOR\n",
        "    else:\n",
        "      l2w.append(\"    if num_tree == %s:\\n\" % 0)\n",
        "      l2w.append(\"        state = %s\\n\" % 0)\n",
        "      if 'RandomForestClassifier' in str(type(self.estimator)):\n",
        "        n_trees = len(self.estimator.estimators_)\n",
        "        for n in range(n_trees):\n",
        "          if n == 0:\n",
        "            l2w = XtracTree.build_dtree_rules(\n",
        "              self.estimator.estimators_[n], \n",
        "              n_trees, self.x_train, l2w)\n",
        "          else:\n",
        "            l2w.append(\"    elif num_tree == %s:\\n\" % n)\n",
        "            l2w.append(\"        state = %s\\n\" % 0)\n",
        "            l2w = XtracTree.build_dtree_rules(\n",
        "              self.estimator.estimators_[n], \n",
        "              n_trees, self.x_train, l2w)\n",
        "          # ENDIF\n",
        "        # ENDFOR\n",
        "      else:\n",
        "        # estimator = DECISION TREE\n",
        "        # PASS IT DIRECTLY TO build_tree_rules\n",
        "        n_trees = 1\n",
        "        l2w = XtracTree.build_dtree_rules(\n",
        "          self.estimator, \n",
        "          n_trees, self.x_train, l2w)\n",
        "      # ENDIF\n",
        "    # ENDIF\n",
        "    # WRITE AT THE BOTTOM THE PREDICT RULE FOR THE XTRACTREE MODEL\n",
        "    l2w.append(\"\\n\\ndef estimator_predict(x):\\n\")\n",
        "    # INITIALIZE PROBA VALUES AT 0\n",
        "    l2w.append(\"    predict = 0.0\\n\")\n",
        "    l2w.append(\"    for i in range(%s):\\n\" % n_trees)\n",
        "    l2w.append(\"        predict += estimator_tree(x, i)\\n\")\n",
        "    if 'LGBM' in str(self.estimator):\n",
        "      l2w.append(\"    predict=(1/(1+np.exp(-predict)))\\n\")\n",
        "    # ENDIF\n",
        "    l2w.append(\"    return predict\\n\")\n",
        "    if self.out is not None:\n",
        "      with open(self.out, 'w') as the_file:\n",
        "        the_file.write(\"\".join(l2w))\n",
        "        the_file.close()\n",
        "      # ENDWITH\n",
        "    else:\n",
        "      print(l2w)\n",
        "    # ENDIF\n",
        "    return None\n",
        "  # END OF FUNCTION build_model\n",
        "  #\n",
        "  def display_rule_per_estimator(\n",
        "      estimator, X_test, sample_id, l2r, ndecisions):\n",
        "    \"\"\"Display the decision path per tree contained in the estimator\n",
        "    for 1 sample.\n",
        "    \"\"\"\n",
        "    n_nodes = estimator.tree_.node_count\n",
        "    children_left = estimator.tree_.children_left\n",
        "    children_right = estimator.tree_.children_right\n",
        "    feature = estimator.tree_.feature\n",
        "    threshold = estimator.tree_.threshold\n",
        "    node_indicator = estimator.decision_path(X_test)\n",
        "    # WE HAVE THE leaves ids REACHED BY EACH SAMPLE\n",
        "    leave_id = estimator.apply(X_test)\n",
        "    node_index = node_indicator.indices[\n",
        "      node_indicator.indptr[sample_id]:node_indicator.indptr[sample_id + 1]]\n",
        "    if ndecisions is None: ndecisions = len(node_index) # ENDIF\n",
        "    node_index = node_index[:ndecisions]\n",
        "    for node_id in node_index:\n",
        "      if leave_id[sample_id] == node_id:\n",
        "        continue\n",
        "      # ENDIF\n",
        "      if (X_test.iloc[sample_id, feature[node_id]] <= threshold[node_id]):\n",
        "        threshold_sign = \"<=\"\n",
        "      else:\n",
        "        threshold_sign = \">\"\n",
        "      # ENDIF\n",
        "      print(\"decision node %s: %s (=%s) %s %s\"\n",
        "        % (node_id,\n",
        "          X_test.columns[feature[node_id]],\n",
        "          X_test.iloc[sample_id, feature[node_id]],\n",
        "          threshold_sign,\n",
        "          np.round(threshold[node_id],4))\n",
        "      )\n",
        "      l2r.append(\n",
        "        [X_test.columns[feature[node_id]], \n",
        "        X_test.iloc[sample_id, feature[node_id]],\n",
        "        threshold[node_id]]\n",
        "    )\n",
        "    # ENDFOR\n",
        "    return l2r\n",
        "  # END OF FUNCTION display_rule_per_estimator\n",
        "  #\n",
        "  def display_rule_per_estimator_sample_ids(estimator, X_test, sample_ids):\n",
        "    \"\"\"Display the decision path per tree contained in the estimator\n",
        "    for a group of samples.\n",
        "    \"\"\"\n",
        "    n_nodes = estimator.tree_.node_count\n",
        "    children_left = estimator.tree_.children_left\n",
        "    children_right = estimator.tree_.children_right\n",
        "    feature = estimator.tree_.feature\n",
        "    threshold = estimator.tree_.threshold\n",
        "    node_indicator = estimator.decision_path(X_test)\n",
        "    # WE HAVE THE leaves ids REACHED BY EACH SAMPLE\n",
        "    leave_id = estimator.apply(X_test)\n",
        "    common_nodes = (\n",
        "      node_indicator.toarray()[sample_ids].sum(axis=0) == len(sample_ids)\n",
        "    )\n",
        "    common_node_id = np.arange(n_nodes)[common_nodes]\n",
        "    print(\"Shared nodes %s,\\n\" % (common_node_id),\n",
        "      \"Shared features %s,\\n\" % (X_test.columns[feature[common_node_id]].values), \n",
        "      \"Shared threshold %s\" % (threshold[common_node_id])\n",
        "    )\n",
        "    print(\"Values:\\n%s\\n\" % (\n",
        "      X_test.iloc[sample_ids, feature[common_node_id]].values)\n",
        "    )\n",
        "    return None\n",
        "  # END OF FUNCTION display_rule_per_estimator_sample_ids\n",
        "  #\n",
        "  def sample_rules(self, ndecisions=None):\n",
        "    \"\"\"Display decision path on demand if sample_id or sample_ids\n",
        "    is not None.\n",
        "    \"\"\"\n",
        "    if 'LGBM' in str(self.estimator):\n",
        "      print('sample_rules for lightgbm not yet implemented.')\n",
        "      return None\n",
        "    # ENDIF\n",
        "    l2r = []\n",
        "    if self.sample_id is not None:\n",
        "      print(\"Rules to predict sample %s\" % self.sample_id)\n",
        "      if 'RandomForestClassifier' in str(type(self.estimator)):\n",
        "        n_trees = len(self.estimator.estimators_)\n",
        "        for n in range(n_trees):\n",
        "          print(\"\\nRules for tree %s\" % n)\n",
        "          l2r = XtracTree.display_rule_per_estimator(\n",
        "            self.estimator.estimators_[n],\n",
        "            self.x_test, self.sample_id, l2r, ndecisions\n",
        "          )\n",
        "        # ENDFOR\n",
        "      else:\n",
        "        # estimator = DECISION TREE\n",
        "        # PASS IT DIRECTLY TO display_rule_per_estimator\n",
        "        l2r = XtracTree.display_rule_per_estimator(\n",
        "          self.estimator, self.x_test, \n",
        "          self.sample_id, l2r, ndecisions\n",
        "        )\n",
        "      # ENDIF\n",
        "      # CONVERT l2r AS A DATAFRAME\n",
        "      l2r = pd.DataFrame(\n",
        "        l2r, \n",
        "        columns=[\n",
        "          'Features', \n",
        "          'Value Sample %s ' % self.sample_id, \n",
        "          'Threshold']\n",
        "      )\n",
        "    # ENDIF\n",
        "    if self.sample_ids is not None:\n",
        "      print(\"\\n\\nRules to predict samples %s\" % self.sample_ids)\n",
        "      if 'RandomForestClassifier' in str(type(self.estimator)):\n",
        "        n_trees = len(self.estimator.estimators_)\n",
        "        for n in range(n_trees):\n",
        "          print(\"\\nRules for tree %s\" % n)\n",
        "          XtracTree.display_rule_per_estimator_sample_ids(\n",
        "            self.estimator.estimators_[n],\n",
        "            self.x_test, self.sample_ids\n",
        "          )\n",
        "        # ENDFOR\n",
        "      else:\n",
        "        # estimator = DECISION TREE\n",
        "        # PASS IT DIRECTLY TO display_rule_per_estimator\n",
        "        XtracTree.display_rule_per_estimator_sample_ids(\n",
        "          self.estimator, self.x_test, self.sample_ids\n",
        "        )\n",
        "      # ENDIF\n",
        "    if len(l2r): return l2r\n",
        "  # END OF FUNCTION sample_rules\n",
        "  #\n",
        "  def _decisions_forest(df_rules, maxlines):\n",
        "    \"\"\"Extract the most recurrent decision rules when estimator\n",
        "    has several trees.\n",
        "    \"\"\"\n",
        "    colfeat = np.unique(df_rules['Features'])\n",
        "    d = Counter(df_rules['Features'])\n",
        "    vals = np.unique(list(d.values())) # COLLECT UNIQUE VALUES\n",
        "    scndval = np.sort(vals)[::-1] # SORT IN DESCENDING ORDER\n",
        "    # FOR LOOP COLLECT TOP KEY FEATURES\n",
        "    sfeat = []\n",
        "    for ival in scndval:\n",
        "      valmax = ival\n",
        "      for ikey in list(d.keys()):\n",
        "        cnd = (d[ikey]==valmax)\n",
        "        if cnd and (not ikey in sfeat): sfeat.append(ikey) # ENDIF\n",
        "      # ENDFOR\n",
        "    # ENDFOR\n",
        "    # COLLECT DECISION THRESHOLDS FOR FEATURES\n",
        "    valsamples, minthreshold = [], []\n",
        "    for ifeat in sfeat:\n",
        "      cnd = (df_rules['Features']==ifeat)\n",
        "      valsamples.append(df_rules[cnd].iloc[:,1].max())\n",
        "      minthreshold.append(df_rules[cnd].iloc[:,2].min())\n",
        "    # ENDFOR\n",
        "    # PROCESS RESULTS\n",
        "    nwdf = {\n",
        "      'Features': sfeat,\n",
        "      'Value Sample': valsamples,\n",
        "      'Threshold': minthreshold\n",
        "    }\n",
        "    nwdf = pd.DataFrame(nwdf)\n",
        "    return nwdf[:np.min((maxlines, len(nwdf)))]\n",
        "  # END OF FUNCTION decisions_forest\n",
        "  #\n",
        "  def decisionsForForest(self, nDecisionsPerTree=5):\n",
        "    \"\"\"Function pipeline to highlight top decisions of forest estimator.\"\"\"\n",
        "    cnd = 'RandomForestClassifier' in str(type(self.estimator))\n",
        "    if not cnd:\n",
        "      msg=\"decisionsForForest only compatible for forest of trees.\\n\"\n",
        "      msg+=\"Current implementation only compatible with RandomForestClassifier.\"\n",
        "      print(msg); return None;\n",
        "    tmpdf = XtracTree.sample_rules(\n",
        "      self, ndecisions=nDecisionsPerTree) # TOP 5 DECISIONS PER TREE\n",
        "    resdf = XtracTree._decisions_forest(\n",
        "      tmpdf, nDecisionsPerTree) # AGGREGATE TOP DECISIONS\n",
        "    return resdf\n",
        "  # END OF FUNCTION decisionsForForest\n",
        "# END OF CLASS XtracTree"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZUUd30VNsoy"
      },
      "source": [
        "# Data Processing\n",
        "For the sake of the demo, we use load_breast_cancer data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQMuPo0y9itc"
      },
      "source": [
        "# DATA IMPORT\n",
        "data=load_breast_cancer()\n",
        "for item in range(len(data.feature_names)):\n",
        "  data.feature_names[item]=data.feature_names[item].replace(' ', '_')\n",
        "df=pd.DataFrame(data.data, columns=data.feature_names)\n",
        "# DATA SPLIT\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df,\n",
        "    data.target,\n",
        "    test_size=0.3,\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOcTg1iBN4-d"
      },
      "source": [
        "# Estimator Definition\n",
        "in this demo, we illustrate XtracTree with a Decision Tree Classifier. By changing exp=1, one can test the notebook for a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVk9I4wmn97P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caeae50d-7048-43b8-e8a4-c1fe19fa600e"
      },
      "source": [
        "exp = 2 # CHOOSE THE EXPERIMENTS YOU WANT TO RUN\n",
        "outfile='estimator_decision_rules.py'\n",
        "if exp == 1:\n",
        "  estimator = RandomForestClassifier(\n",
        "    n_estimators=4, max_depth=None,\n",
        "    max_features='auto', n_jobs=-1, random_state=0)\n",
        "elif exp == 3:\n",
        "  estimator=lightgbm.LGBMClassifier(\n",
        "    max_depth=3,\n",
        "    n_estimators=3,\n",
        "    objective=\"binary\"\n",
        "  )\n",
        "else:\n",
        "  estimator = DecisionTreeClassifier(\n",
        "    max_depth=10, max_features='auto', random_state=0)\n",
        "# ENDIF\n",
        "estimator.fit(X_train, y_train) # MODEL FIT\n",
        "#\n",
        "# we convert the features importance of the classifier to a df\n",
        "# d = {'Features': X_train.columns, \n",
        "#      'Feat Imp': estimator.feature_importances_\n",
        "# }\n",
        "# estimatorFeatimportance = pd.DataFrame(d).sort_values(\n",
        "#     by='Feat Imp', ascending=False\n",
        "# )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(max_depth=10, max_features='auto', random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy7VtT5tONl5"
      },
      "source": [
        "# XtracTree\n",
        "XtracTree is first initialized with the trained estimator, the train set and the test set. Then, the desicion rules of the estimator are extracted and saved in the file estimator_decision_rules.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dui55HojpAYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1974e7-1e19-4873-9a2b-87036a6d13a6"
      },
      "source": [
        "p = XtracTree(estimator, X_train, X_test, out=outfile)\n",
        "p.build_model()\n",
        "#\n",
        "# output the contents of estimator_decision_rules.py\n",
        "file1 = open(outfile, 'r')\n",
        "Lines = file1.readlines()\n",
        "count = 0\n",
        "print(\"!!! Contents written in \"+outfile+\" by XtracTree !!!\\n\\n\")\n",
        "for line in Lines:\n",
        "    count += 1\n",
        "    print(\"{} {}\".format(count, line))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! Contents written in estimator_decision_rules.py by XtracTree !!!\n",
            "\n",
            "\n",
            "1 import numpy as np\n",
            "\n",
            "2 \n",
            "\n",
            "3 def estimator_tree(x, num_tree):\n",
            "\n",
            "4     if num_tree == 0:\n",
            "\n",
            "5         state = 0\n",
            "\n",
            "6         if state == 0: state = (1 if x['mean_concave_points'] <= 0.05127999931573868 else 28)\n",
            "\n",
            "7         if state == 1: state = (2 if x['area_error'] <= 38.415000915527344 else 21)\n",
            "\n",
            "8         if state == 2: state = (3 if x['worst_radius'] <= 17.739999771118164 else 16)\n",
            "\n",
            "9         if state == 3: state = (4 if x['worst_perimeter'] <= 101.54999923706055 else 11)\n",
            "\n",
            "10         if state == 4: state = (5 if x['mean_texture'] <= 22.454999923706055 else 6)\n",
            "\n",
            "11         if state == 5: return 1.0\n",
            "\n",
            "12         if state == 6: state = (7 if x['worst_smoothness'] <= 0.14124999940395355 else 8)\n",
            "\n",
            "13         if state == 7: return 1.0\n",
            "\n",
            "14         if state == 8: state = (9 if x['worst_perimeter'] <= 89.08000183105469 else 10)\n",
            "\n",
            "15         if state == 9: return 1.0\n",
            "\n",
            "16         if state == 10: return 0.0\n",
            "\n",
            "17         if state == 11: state = (12 if x['worst_perimeter'] <= 103.0999984741211 else 13)\n",
            "\n",
            "18         if state == 12: return 0.0\n",
            "\n",
            "19         if state == 13: state = (14 if x['worst_smoothness'] <= 0.14124999940395355 else 15)\n",
            "\n",
            "20         if state == 14: return 1.0\n",
            "\n",
            "21         if state == 15: return 0.0\n",
            "\n",
            "22         if state == 16: state = (17 if x['mean_texture'] <= 18.835000038146973 else 20)\n",
            "\n",
            "23         if state == 17: state = (18 if x['worst_smoothness'] <= 0.14145000278949738 else 19)\n",
            "\n",
            "24         if state == 18: return 1.0\n",
            "\n",
            "25         if state == 19: return 0.0\n",
            "\n",
            "26         if state == 20: return 0.0\n",
            "\n",
            "27         if state == 21: state = (22 if x['mean_symmetry'] <= 0.16565000265836716 else 27)\n",
            "\n",
            "28         if state == 22: state = (23 if x['symmetry_error'] <= 0.021220000460743904 else 26)\n",
            "\n",
            "29         if state == 23: state = (24 if x['mean_area'] <= 962.5999755859375 else 25)\n",
            "\n",
            "30         if state == 24: return 0.0\n",
            "\n",
            "31         if state == 25: return 1.0\n",
            "\n",
            "32         if state == 26: return 1.0\n",
            "\n",
            "33         if state == 27: return 1.0\n",
            "\n",
            "34         if state == 28: state = (29 if x['worst_concave_points'] <= 0.1465499997138977 else 34)\n",
            "\n",
            "35         if state == 29: state = (30 if x['worst_perimeter'] <= 115.25 else 33)\n",
            "\n",
            "36         if state == 30: state = (31 if x['worst_texture'] <= 26.5649995803833 else 32)\n",
            "\n",
            "37         if state == 31: return 1.0\n",
            "\n",
            "38         if state == 32: return 0.0\n",
            "\n",
            "39         if state == 33: return 0.0\n",
            "\n",
            "40         if state == 34: state = (35 if x['mean_area'] <= 330.90000915527344 else 36)\n",
            "\n",
            "41         if state == 35: return 1.0\n",
            "\n",
            "42         if state == 36: state = (37 if x['mean_concavity'] <= 0.2958499938249588 else 38)\n",
            "\n",
            "43         if state == 37: return 0.0\n",
            "\n",
            "44         if state == 38: state = (39 if x['mean_smoothness'] <= 0.093384999781847 else 40)\n",
            "\n",
            "45         if state == 39: return 1.0\n",
            "\n",
            "46         if state == 40: return 0.0\n",
            "\n",
            "47 \n",
            "\n",
            "48 \n",
            "\n",
            "49 def estimator_predict(x):\n",
            "\n",
            "50     predict = 0.0\n",
            "\n",
            "51     for i in range(1):\n",
            "\n",
            "52         predict += estimator_tree(x, i)\n",
            "\n",
            "53     return predict\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vopQbKpQOkS7"
      },
      "source": [
        "Using the custom funtion estimator_predict(*args) generated in estimator_decision_rules.py, XtracTree can replicate exactly the predictive performance of the trained ML estimator simply using the rules-based model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N30g_TGZpMgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "30f4a68a-68e5-40cf-a7f3-9557bc30a338"
      },
      "source": [
        "from estimator_decision_rules import estimator_predict\n",
        "\n",
        "sample_ids = [0,1,2,3,4,5]\n",
        "res_from_parser = np.zeros((len(sample_ids)))\n",
        "for n in range(len(sample_ids)):\n",
        "  sample_id = sample_ids[n]\n",
        "  sample_proba = estimator_predict(X_test.iloc[sample_id, :])\n",
        "  res_from_parser[n] = sample_proba\n",
        "\n",
        "d = {\"sample\": sample_ids, \n",
        "     \"Proba from XtracTree\": res_from_parser, \n",
        "     \"Proba from AI classifier\": estimator.predict_proba(X_test)[:, 1][sample_ids]}\n",
        "pd.DataFrame(d)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1938f66-ab09-4933-8ddd-27ffa93bc277\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample</th>\n",
              "      <th>Proba from XtracTree</th>\n",
              "      <th>Proba from AI classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1938f66-ab09-4933-8ddd-27ffa93bc277')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1938f66-ab09-4933-8ddd-27ffa93bc277 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1938f66-ab09-4933-8ddd-27ffa93bc277');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sample  Proba from XtracTree  Proba from AI classifier\n",
              "0       0                   1.0                       1.0\n",
              "1       1                   0.0                       0.0\n",
              "2       2                   0.0                       0.0\n",
              "3       3                   1.0                       1.0\n",
              "4       4                   1.0                       1.0\n",
              "5       5                   0.0                       0.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXmmrYFacT3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "dd84a111-9d00-48cd-d27a-74dda5d886bc"
      },
      "source": [
        "sample_ids = np.arange(0, len(X_test[:15000]))\n",
        "res_from_parser = np.zeros((len(sample_ids)))\n",
        "for n in range(len(sample_ids)):\n",
        "  sample_id = sample_ids[n]\n",
        "  sample_proba = estimator_predict(X_test.iloc[sample_id, :])\n",
        "  res_from_parser[n] = sample_proba\n",
        "\n",
        "d = {\"sample\": sample_ids, \n",
        "     \"Proba from XtracTree\": res_from_parser, \n",
        "     \"Proba from AI classifier\": estimator.predict_proba(X_test)[:, 1][sample_ids]}\n",
        "pd.DataFrame(d).describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8507bbde-67ee-4a18-b048-667f9437a482\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample</th>\n",
              "      <th>Proba from XtracTree</th>\n",
              "      <th>Proba from AI classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>171.000000</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>171.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.608187</td>\n",
              "      <td>0.608187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>49.507575</td>\n",
              "      <td>0.489589</td>\n",
              "      <td>0.489589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>42.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>85.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>127.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>170.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8507bbde-67ee-4a18-b048-667f9437a482')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8507bbde-67ee-4a18-b048-667f9437a482 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8507bbde-67ee-4a18-b048-667f9437a482');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           sample  Proba from XtracTree  Proba from AI classifier\n",
              "count  171.000000            171.000000                171.000000\n",
              "mean    85.000000              0.608187                  0.608187\n",
              "std     49.507575              0.489589                  0.489589\n",
              "min      0.000000              0.000000                  0.000000\n",
              "25%     42.500000              0.000000                  0.000000\n",
              "50%     85.000000              1.000000                  1.000000\n",
              "75%    127.500000              1.000000                  1.000000\n",
              "max    170.000000              1.000000                  1.000000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpwGkIBqh0bi"
      },
      "source": [
        "# Decision path on demand\n",
        "With XtracTree, one can highlight the complex decision process that led to the predictions. In other words, the decision path can be outputed for one sample or for a group of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDyUzWXuwVAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac4a9a3-90b2-4a99-d566-9ef529dbaadc"
      },
      "source": [
        "p = XtracTree(estimator, X_train, X_test, sample_id=6, sample_ids=[0,1,2])\n",
        "df_rules = p.sample_rules()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rules to predict sample 6\n",
            "decision node 0: mean_concave_points (=0.1501) > 0.0513\n",
            "decision node 28: worst_concave_points (=0.2432) > 0.1465\n",
            "decision node 34: mean_area (=1482.0) > 330.9\n",
            "decision node 36: mean_concavity (=0.2448) <= 0.2958\n",
            "\n",
            "\n",
            "Rules to predict samples [0, 1, 2]\n",
            "Shared nodes [0],\n",
            " Shared features ['mean_concave_points'],\n",
            " Shared threshold [0.05128]\n",
            "Values:\n",
            "[[0.03821]\n",
            " [0.07951]\n",
            " [0.08087]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}