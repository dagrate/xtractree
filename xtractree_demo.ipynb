{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xtractree_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SOUsvK3M6pk"
      },
      "source": [
        "# How to use XtracTree?\n",
        "In this notebook, we demonstrate the usage of XtracTree for a Decision Tree Classifier. Parameter \"exp\" can be adjusted to do the experiments with a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUJRPnMhn45U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (classification_report, \n",
        "                             confusion_matrix, \n",
        "                             roc_curve, \n",
        "                             auc)\n",
        "from sklearn.utils import Bunch\n",
        "import pickle as pkl\n",
        "\n",
        "# pandas options\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuqrWN_jNfeJ"
      },
      "source": [
        "# XtracTree Class Definition\n",
        "Here we pasted the XtracTree class in the notebook for the sake of the demo. It is possible to save the class in a separate module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np9nYnCgn8A2"
      },
      "source": [
        "class XtracTree:\n",
        "    def __init__(self, estimator, x_train, x_test, \n",
        "                 sample_id=None, sample_ids=None, out=None):\n",
        "        self.estimator = estimator\n",
        "        self.x_train = x_train\n",
        "        self.x_test = x_test\n",
        "        self.sample_id = sample_id\n",
        "        self.sample_ids = sample_ids\n",
        "        self.out = out\n",
        "\n",
        "\n",
        "    def build_dtree_rules(estimator, n_trees, x_train, l2w):\n",
        "        \"\"\"Extract decision rules with splitting thresholds and probabilities.\n",
        "        \"\"\"\n",
        "        # we can get useful information about the tree structure\n",
        "        # using estimator.tree.__getstate__()['nodes']\n",
        "        # or import sklearn, help(sklearn.tree._tree.Tree)\n",
        "        n_nodes = estimator.tree_.node_count\n",
        "        children_left = estimator.tree_.children_left\n",
        "        children_right = estimator.tree_.children_right\n",
        "        feature = estimator.tree_.feature\n",
        "        threshold = estimator.tree_.threshold\n",
        "        n_node_samples = estimator.tree_.n_node_samples\n",
        "        value = estimator.tree_.value \n",
        "        weighted_n_node_samples = estimator.tree_.weighted_n_node_samples\n",
        "\n",
        "        node_depth = np.zeros(shape = n_nodes, dtype = np.int64)\n",
        "        is_leaves = np.zeros(shape = n_nodes, dtype = bool)\n",
        "        stack = [(0, -1)] # seed is the root node id and its parent depth\n",
        "\n",
        "        while len(stack) > 0:\n",
        "            node_id, parent_depth = stack.pop()\n",
        "            node_depth[node_id] = parent_depth + 1\n",
        "\n",
        "            # if we have a test node\n",
        "            if (children_left[node_id] != children_right[node_id]):\n",
        "                stack.append((children_left[node_id], parent_depth + 1))\n",
        "                stack.append((children_right[node_id], parent_depth + 1))\n",
        "            else:\n",
        "                is_leaves[node_id] = True\n",
        "\n",
        "        for i in range(n_nodes):\n",
        "            if is_leaves[i]:\n",
        "                # irow = \"%sif state == %s:\\n%sprint(state)\\n%sreturn %s\\n\" % ((\n",
        "                irow = \"        if state == %s: return %s\\n\" % (\n",
        "                    i, ((value[i][0,1] / weighted_n_node_samples[i]) / n_trees)\n",
        "                    )\n",
        "            else:\n",
        "                irow = \"        if state == %s: state = (%s if x['%s'] <= %s else %s)\\n\" % (\n",
        "                    i, \n",
        "                    children_left[i],\n",
        "                    x_train.columns[feature[i]],\n",
        "                    threshold[i],\n",
        "                    children_right[i]\n",
        "                )\n",
        "            l2w.append(irow)\n",
        "        return l2w\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Build the global architecture of the bagging algorithm.\n",
        "        It is designed such that it is an executable if self.out is \n",
        "        saved as .py file. \n",
        "        \"\"\"\n",
        "        # we write the first line of the file\n",
        "        # we store the content of the file to be written in l2w\n",
        "        l2w = [\"import numpy as np\\n\"]\n",
        "        l2w.append(\"\\n\")\n",
        "        l2w.append(\"def estimator_tree(x, num_tree):\\n\")\n",
        "        l2w.append(\"    if num_tree == %s:\\n\" % 0)\n",
        "        l2w.append(\"        state = %s\\n\" % 0)\n",
        "\n",
        "        if 'RandomForestClassifier' in str(type(self.estimator)):\n",
        "            n_trees = len(self.estimator.estimators_)\n",
        "            for n in range(n_trees):\n",
        "                if n == 0:\n",
        "                    l2w = XtracTree.build_dtree_rules(\n",
        "                        self.estimator.estimators_[n], \n",
        "                        n_trees, self.x_train, l2w)\n",
        "                else:\n",
        "                    l2w.append(\"    elif num_tree == %s:\\n\" % n)\n",
        "                    l2w.append(\"        state = %s\\n\" % 0)\n",
        "                    l2w = XtracTree.build_dtree_rules(\n",
        "                        self.estimator.estimators_[n], \n",
        "                        n_trees, self.x_train, l2w)\n",
        "        else:\n",
        "            # the estimator is a decision tree\n",
        "            # we can pass it directly to build_tree_rules\n",
        "            n_trees = 1\n",
        "            l2w = XtracTree.build_dtree_rules(\n",
        "                        self.estimator, \n",
        "                        n_trees, self.x_train, l2w)\n",
        "        \n",
        "        # we write at the bottom the predict rule for the fixed model\n",
        "        l2w.append(\"\\n\\ndef estimator_predict(x):\\n\")\n",
        "\n",
        "        # we initialize the proba values at 0\n",
        "        l2w.append(\"    predict = 0.0\\n\")\n",
        "        l2w.append(\"    for i in range(%s):\\n\" % n_trees)\n",
        "        l2w.append(\"        predict += estimator_tree(x, i)\\n\")\n",
        "        l2w.append(\"    return predict\\n\")\n",
        "\n",
        "        if self.out is not None:\n",
        "            with open(self.out, 'w') as the_file:\n",
        "                the_file.write(\"\".join(l2w))\n",
        "                the_file.close()\n",
        "        else:\n",
        "            print(l2w)\n",
        "        \n",
        "        return None\n",
        "\n",
        "\n",
        "    def display_rule_per_estimator(estimator, X_test, sample_id, l2r):\n",
        "        \"\"\"Display the decision path per tree contained in the estimator for 1 sample.\n",
        "        \"\"\"\n",
        "        n_nodes = estimator.tree_.node_count\n",
        "        children_left = estimator.tree_.children_left\n",
        "        children_right = estimator.tree_.children_right\n",
        "        feature = estimator.tree_.feature\n",
        "        threshold = estimator.tree_.threshold\n",
        "        node_indicator = estimator.decision_path(X_test)\n",
        "        \n",
        "        # we have the leaves ids reached by each sample.\n",
        "        leave_id = estimator.apply(X_test)\n",
        "\n",
        "        node_index = node_indicator.indices[node_indicator.indptr[sample_id]:\n",
        "                                                                        node_indicator.indptr[sample_id + 1]]\n",
        "        \n",
        "        for node_id in node_index:\n",
        "            if leave_id[sample_id] == node_id:\n",
        "                continue\n",
        "\n",
        "            if (X_test.iloc[sample_id, feature[node_id]] <= threshold[node_id]):\n",
        "                threshold_sign = \"<=\"\n",
        "            else:\n",
        "                threshold_sign = \">\"\n",
        "\n",
        "            print(\"decision node %s: %s (=%s) %s %s\"\n",
        "                        % (node_id,\n",
        "                                X_test.columns[feature[node_id]],\n",
        "                                X_test.iloc[sample_id, feature[node_id]],\n",
        "                                threshold_sign,\n",
        "                                np.round(threshold[node_id],4)))\n",
        "            l2r.append(\n",
        "                    [X_test.columns[feature[node_id]], \n",
        "                    X_test.iloc[sample_id, feature[node_id]],\n",
        "                    threshold[node_id]]\n",
        "            )\n",
        "        return l2r\n",
        "\n",
        "\n",
        "    def display_rule_per_estimator_sample_ids(estimator, X_test, sample_ids):\n",
        "        \"\"\"Display the decision path per tree contained in the estimator for a group of samples.\n",
        "        \"\"\"\n",
        "        n_nodes = estimator.tree_.node_count\n",
        "        children_left = estimator.tree_.children_left\n",
        "        children_right = estimator.tree_.children_right\n",
        "        feature = estimator.tree_.feature\n",
        "        threshold = estimator.tree_.threshold\n",
        "        node_indicator = estimator.decision_path(X_test)\n",
        "        \n",
        "        # we have the leaves ids reached by each sample.\n",
        "        leave_id = estimator.apply(X_test)\n",
        "\n",
        "        common_nodes = (node_indicator.toarray()[sample_ids].sum(axis=0) ==\n",
        "                                        len(sample_ids))\n",
        "\n",
        "        common_node_id = np.arange(n_nodes)[common_nodes]\n",
        "\n",
        "        print(\"Shared nodes %s,\" % (common_node_id),\n",
        "                    \"Shared features %s,\" % (\n",
        "                        X_test.columns[feature[common_node_id]].values), \n",
        "                    \"Shared threshold %s\" % (threshold[common_node_id]\n",
        "                    )\n",
        "        )\n",
        "        print(\"Values:\\n%s\" % (X_test.iloc[sample_ids, feature[common_node_id]].values))\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "    def sample_rules(self):\n",
        "        \"\"\"Display decision path on demand if sample_id or sample_ids is not None.\n",
        "        \"\"\"\n",
        "        l2r = []\n",
        "\n",
        "        if self.sample_id is not None:\n",
        "            print(\"Rules to predict sample %s\" % self.sample_id)\n",
        "            if 'RandomForestClassifier' in str(type(self.estimator)):\n",
        "                n_trees = len(self.estimator.estimators_)\n",
        "                for n in range(n_trees):\n",
        "                    print(\"\\nRules for tree %s\" % n)\n",
        "                    l2r = XtracTree.display_rule_per_estimator(\n",
        "                            self.estimator.estimators_[n],\n",
        "                            self.x_test, self.sample_id, l2r\n",
        "                    )\n",
        "            else:\n",
        "                # the estimator is a decision tree\n",
        "                # we can pass it directly to display_rule_per_estimator\n",
        "                l2r = XtracTree.display_rule_per_estimator(\n",
        "                            self.estimator, self.x_test, \n",
        "                            self.sample_id, l2r\n",
        "                )\n",
        "            \n",
        "            # we convert l2r as a dataframe\n",
        "            l2r = pd.DataFrame(l2r, \n",
        "                               columns=['Features', \n",
        "                                        'Value Sample %s ' % self.sample_id, \n",
        "                                        'Threshold']\n",
        "            )\n",
        "            \n",
        "        if self.sample_ids is not None:\n",
        "            print(\"\\n\\nRules to predict samples %s\" % self.sample_ids)\n",
        "            if 'RandomForestClassifier' in str(type(self.estimator)):\n",
        "                n_trees = len(self.estimator.estimators_)\n",
        "                for n in range(n_trees):\n",
        "                    print(\"\\nRules for tree %s\" % n)\n",
        "                    XtracTree.display_rule_per_estimator_sample_ids(\n",
        "                        self.estimator.estimators_[n],\n",
        "                        self.x_test, self.sample_ids\n",
        "                    )\n",
        "            else:\n",
        "                # the estimator is a decision tree\n",
        "                # we can pass it directly to display_rule_per_estimator\n",
        "                XtracTree.display_rule_per_estimator_sample_ids(\n",
        "                    self.estimator, self.x_test, self.sample_ids\n",
        "                )\n",
        "\n",
        "        if len(l2r): return l2r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZUUd30VNsoy"
      },
      "source": [
        "# Data Processing\n",
        "Data was pre-processed and save in .pkl file called loanForExp.pkl."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQMuPo0y9itc"
      },
      "source": [
        "# we import the pkl file containing the data\n",
        "loanForExp = pkl.load(open('loanForExp.pkl','rb'), encoding='latin1')\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    loanForExp.data,\n",
        "    loanForExp.target,\n",
        "    test_size=0.3,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOcTg1iBN4-d"
      },
      "source": [
        "# Estimator Definition\n",
        "in this demo, we illustrate XtracTree with a Decision Tree Classifier. By changing exp=1, one can test the notebook for a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVk9I4wmn97P"
      },
      "source": [
        "exp = 2\n",
        "if exp == 1:\n",
        "    estimator = (\n",
        "        RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=2, max_features=2,\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=3,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "    )\n",
        "else:\n",
        "    estimator = (\n",
        "        DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, \n",
        "                      criterion='gini', max_depth=10, max_features=50, \n",
        "                      max_leaf_nodes=30, min_impurity_decrease=0.0, \n",
        "                      min_impurity_split=None, min_samples_leaf=1, \n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0, \n",
        "                      presort='deprecated', random_state=0, splitter='best')\n",
        "    )\n",
        "\n",
        "estimator.fit(X_train, y_train) # model fit\n",
        "\n",
        "# we convert the features importance of the classifier to a df\n",
        "d = {'Features': X_train.columns, \n",
        "     'Feat Imp': estimator.feature_importances_\n",
        "}\n",
        "estimatorFeatimportance = pd.DataFrame(d).sort_values(\n",
        "    by='Feat Imp', ascending=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy7VtT5tONl5"
      },
      "source": [
        "# XtracTree\n",
        "XtracTree is first initialized with the trained estimator, the train set and the test set. Then, the desicion rules of the estimator are extracted and saved in the file estimator_decision_rules.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dui55HojpAYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21459ba8-f4c2-4fcb-bb6e-d77a0d362ee0"
      },
      "source": [
        "p = XtracTree(estimator, X_train, X_test, out='estimator_decision_rules.py')\n",
        "p.build_model()\n",
        "#\n",
        "# output the contents of estimator_decision_rules.py\n",
        "file1 = open('estimator_decision_rules.py', 'r')\n",
        "Lines = file1.readlines()\n",
        "count = 0\n",
        "print(\"!!! Contents written in estimator_decision_rules.py by XtracTree !!!\\n\\n\")\n",
        "for line in Lines:\n",
        "    count += 1\n",
        "    print(\"{} {}\".format(count, line))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! Contents written in estimator_decision_rules.py by XtracTree !!!\n",
            "\n",
            "\n",
            "1 import numpy as np\n",
            "\n",
            "2 \n",
            "\n",
            "3 def estimator_tree(x, num_tree):\n",
            "\n",
            "4     if num_tree == 0:\n",
            "\n",
            "5         state = 0\n",
            "\n",
            "6         if state == 0: state = (1 if x['total_rec_prncp'] <= 998.0950012207031 else 2)\n",
            "\n",
            "7         if state == 1: return 1.0\n",
            "\n",
            "8         if state == 2: state = (3 if x['out_prncp'] <= 13385.35546875 else 4)\n",
            "\n",
            "9         if state == 3: state = (5 if x['total_rec_prncp'] <= 1191.5700073242188 else 6)\n",
            "\n",
            "10         if state == 4: return 1.0\n",
            "\n",
            "11         if state == 5: state = (7 if x['loan_amnt'] <= 5550.0 else 8)\n",
            "\n",
            "12         if state == 6: state = (9 if x['total_rec_int'] <= 0.16500000655651093 else 10)\n",
            "\n",
            "13         if state == 7: return 0.0\n",
            "\n",
            "14         if state == 8: return 1.0\n",
            "\n",
            "15         if state == 9: state = (11 if x['il_util'] <= 88.5 else 12)\n",
            "\n",
            "16         if state == 10: state = (19 if x['last_pymnt_amnt'] <= 1347.9049682617188 else 20)\n",
            "\n",
            "17         if state == 11: state = (13 if x['all_util'] <= 92.0 else 14)\n",
            "\n",
            "18         if state == 12: return 1.0\n",
            "\n",
            "19         if state == 13: state = (15 if x['total_acc'] <= 8.5 else 16)\n",
            "\n",
            "20         if state == 14: return 1.0\n",
            "\n",
            "21         if state == 15: state = (17 if x['total_bc_limit'] <= 22700.0 else 18)\n",
            "\n",
            "22         if state == 16: return 0.0\n",
            "\n",
            "23         if state == 17: return 0.0\n",
            "\n",
            "24         if state == 18: return 1.0\n",
            "\n",
            "25         if state == 19: state = (21 if x['last_pymnt_amnt'] <= 1339.5049438476562 else 22)\n",
            "\n",
            "26         if state == 20: return 0.0\n",
            "\n",
            "27         if state == 21: state = (23 if x['installment'] <= 1250.4500122070312 else 24)\n",
            "\n",
            "28         if state == 22: return 1.0\n",
            "\n",
            "29         if state == 23: state = (27 if x['installment'] <= 974.14501953125 else 28)\n",
            "\n",
            "30         if state == 24: state = (25 if x['tot_hi_cred_lim'] <= 169620.5 else 26)\n",
            "\n",
            "31         if state == 25: return 1.0\n",
            "\n",
            "32         if state == 26: return 0.0\n",
            "\n",
            "33         if state == 27: state = (31 if x['mo_sin_old_il_acct'] <= 262.0 else 32)\n",
            "\n",
            "34         if state == 28: state = (29 if x['total_bal_il'] <= 83515.5 else 30)\n",
            "\n",
            "35         if state == 29: return 0.0\n",
            "\n",
            "36         if state == 30: return 1.0\n",
            "\n",
            "37         if state == 31: state = (35 if x['mths_since_rcnt_il'] <= 79.0 else 36)\n",
            "\n",
            "38         if state == 32: state = (33 if x['total_bc_limit'] <= 35550.0 else 34)\n",
            "\n",
            "39         if state == 33: return 0.0\n",
            "\n",
            "40         if state == 34: return 1.0\n",
            "\n",
            "41         if state == 35: return 0.0\n",
            "\n",
            "42         if state == 36: return 0.058823529411764705\n",
            "\n",
            "43 \n",
            "\n",
            "44 \n",
            "\n",
            "45 def estimator_predict(x):\n",
            "\n",
            "46     predict = 0.0\n",
            "\n",
            "47     for i in range(1):\n",
            "\n",
            "48         predict += estimator_tree(x, i)\n",
            "\n",
            "49     return predict\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vopQbKpQOkS7"
      },
      "source": [
        "Using the custom funtion estimator_predict(*args) generated in estimator_decision_rules.py, XtracTree can replicate exactly the predictive performance of the trained ML estimator simply using the rules-based model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N30g_TGZpMgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "2705625a-f978-4494-de47-810dd3b8b34b"
      },
      "source": [
        "from estimator_decision_rules import estimator_predict\n",
        "\n",
        "sample_ids = [0,1,2,3,4,5]\n",
        "res_from_parser = np.zeros((len(sample_ids)))\n",
        "for n in range(len(sample_ids)):\n",
        "  sample_id = sample_ids[n]\n",
        "  sample_proba = estimator_predict(X_test.iloc[sample_id, :])\n",
        "  res_from_parser[n] = sample_proba\n",
        "\n",
        "d = {\"sample\": sample_ids, \n",
        "     \"Proba from XtracTree\": res_from_parser, \n",
        "     \"Proba from DT classifier\": estimator.predict_proba(X_test)[:, 1][sample_ids]}\n",
        "pd.DataFrame(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample</th>\n",
              "      <th>Proba from XtracTree</th>\n",
              "      <th>Proba from DT classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample  Proba from XtracTree  Proba from DT classifier\n",
              "0       0                   0.0                       0.0\n",
              "1       1                   0.0                       0.0\n",
              "2       2                   0.0                       0.0\n",
              "3       3                   0.0                       0.0\n",
              "4       4                   0.0                       0.0\n",
              "5       5                   0.0                       0.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXmmrYFacT3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "8ce2af5f-00fb-45f0-c95e-f960602ed173"
      },
      "source": [
        "sample_ids = np.arange(0, len(X_test[:15000]))\n",
        "res_from_parser = np.zeros((len(sample_ids)))\n",
        "for n in range(len(sample_ids)):\n",
        "  sample_id = sample_ids[n]\n",
        "  sample_proba = estimator_predict(X_test.iloc[sample_id, :])\n",
        "  res_from_parser[n] = sample_proba\n",
        "\n",
        "d = {\"sample\": sample_ids, \n",
        "     \"Proba from XtracTree\": res_from_parser, \n",
        "     \"Proba from DT classifier\": estimator.predict_proba(X_test)[:, 1][sample_ids]}\n",
        "pd.DataFrame(d).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample</th>\n",
              "      <th>Proba from XtracTree</th>\n",
              "      <th>Proba from DT classifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1499.500000</td>\n",
              "      <td>0.049471</td>\n",
              "      <td>0.049471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>866.169729</td>\n",
              "      <td>0.216586</td>\n",
              "      <td>0.216586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>749.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1499.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2249.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2999.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sample  Proba from XtracTree  Proba from DT classifier\n",
              "count  3000.000000           3000.000000               3000.000000\n",
              "mean   1499.500000              0.049471                  0.049471\n",
              "std     866.169729              0.216586                  0.216586\n",
              "min       0.000000              0.000000                  0.000000\n",
              "25%     749.750000              0.000000                  0.000000\n",
              "50%    1499.500000              0.000000                  0.000000\n",
              "75%    2249.250000              0.000000                  0.000000\n",
              "max    2999.000000              1.000000                  1.000000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpwGkIBqh0bi"
      },
      "source": [
        "# Decision path on demand\n",
        "With XtracTree, one can highlight the complex decision process that led to the predictions. In other words, the decision path can be outputed for one sample or for a group of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDyUzWXuwVAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413d5a5b-392f-4613-8222-b702fef362bf"
      },
      "source": [
        "p = XtracTree(estimator, X_train, X_test, sample_id=6, sample_ids=[0,1,2])\n",
        "df_rules = p.sample_rules()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rules to predict sample 6\n",
            "decision node 0: total_rec_prncp (=10000.0) > 998.095\n",
            "decision node 2: out_prncp (=0.0) <= 13385.3555\n",
            "decision node 3: total_rec_prncp (=10000.0) > 1191.57\n",
            "decision node 6: total_rec_int (=230.29) > 0.165\n",
            "decision node 10: last_pymnt_amnt (=9898.17) > 1347.905\n",
            "\n",
            "\n",
            "Rules to predict samples [0, 1, 2]\n",
            "Shared nodes [ 0  2  3  6 10 20], Shared features ['total_rec_prncp' 'out_prncp' 'total_rec_prncp' 'total_rec_int'\n",
            " 'last_pymnt_amnt' 'total_bc_limit'], Shared threshold [ 9.98095001e+02  1.33853555e+04  1.19157001e+03  1.65000007e-01\n",
            "  1.34790497e+03 -2.00000000e+00]\n",
            "Values:\n",
            "[[ 8000.       0.    8000.     637.5   7473.88 18100.  ]\n",
            " [15000.       0.   15000.     587.33 14075.93 11500.  ]\n",
            " [ 4500.       0.    4500.     130.69  4635.67 17000.  ]]\n"
          ]
        }
      ]
    }
  ]
}